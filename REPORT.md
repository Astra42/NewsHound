# Отчет по данным


## Ссылка на репозиторий:
https://github.com/Astra42/NewsHound/

Работа к чекпоинту сохранена в ветке develop

## Откуда берем данные

Данные собираем напрямую из Telegram-каналов крупных новостных изданий:

- @tass_agency (ТАСС)
- @rian_ru (РИА Новости)
- @kommersant (Коммерсантъ)
- @meduzalive (Медуза)
- @rbc_news (РБК)

Для доступа используется Telegram API через библиотеку Telethon. Нужны ключи APP_ID_TG и API_HASH_TG в .env файле.

## Как собираем

Подключаемся к Telegram, проходим по каждому каналу и вытаскиваем последние 100 сообщений. Из каждого поста берем текст, id сообщения, название канала и дату публикации.

Перед сохранением текст чистим:
- убираем ссылки и HTML-теги
- удаляем эмодзи и лишние символы
- выкидываем стоп-слова (предлоги, союзы и т.д.)

## Где хранятся данные

Сейчас данные загружаются в векторное хранилище FAISS прямо в память для семантического поиска.

Весь процесс сбора и индексации находится в файле `rag/index_bd.ipynb`.

## Подготовка для RAG

Тексты нарезаем на куски по 500 символов с небольшим перекрытием (50 символов), чтобы не терять контекст на границах. Используем RecursiveCharacterTextSplitter из LangChain.

Каждый кусок превращаем в вектор с помощью модели BAAI/bge-m3 (протестируем еще другие модели в процессе разработки)

Итоговая структура документа:
```
{
  "content": "текст новости",
  "metadata": {
    "source": "telegram",
    "channel": "@tass_agency", 
    "date": "2025-12-05T10:30:00"
  }
}
```

При поиске берем 5 самых похожих документов и отдаем их в Mistral для генерации ответа.

## Объем данных

- 5 активных каналов
- Около 450 сообщений за один запуск
- Примерно 90 постов с каждого канала

## Где посмотреть примеры

Сэмплы собранных данных можно посмотреть в ноутбуке `rag/index_bd.ipynb` — там в ячейках 5-6 выводятся примеры загруженных документов после обработки.

